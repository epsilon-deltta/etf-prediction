{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7538d0-3c3b-434f-986e-c69d62319d7a",
   "metadata": {},
   "source": [
    "### End2End "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ee849b-e840-4ba4-b94d-92ffa7f38f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense , Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from sklearn import preprocessing\n",
    "# pip install -U finance-datareader\n",
    "# import FinanceDataReader as fdr\n",
    "def make_sequence_dataset(feature, label, window_size):\n",
    "    feature_list = [] \n",
    "    label_list = []\n",
    "\n",
    "    for i in range(len(feature) - window_size):\n",
    "        feature_list.append(feature[i:i+window_size+1]) # added label\n",
    "        label_list.append(label[i+window_size])\n",
    "\n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "def survive_open(x,feature_cols,label_cols):\n",
    "    \n",
    "    index = [i for i,item in enumerate(feature_cols) if (item not in label_cols)]\n",
    "    for i in range(len(x)):\n",
    "        x[i][40][index] = np.zeros(len(index))\n",
    "    return x\n",
    "\n",
    "\n",
    "feature_cols = ['Close', 'Open', 'High', 'Low', 'Volume', 'Change']\n",
    "label_cols = ['High','Low']\n",
    "def train_save(df,recent_date,save_dir='./models'):\n",
    "    \n",
    "    raw_df = df\n",
    "    scaler = MinMaxScaler()\n",
    "    scale_cols = ['Close', 'Open', 'High', 'Low', 'Volume', 'Change']\n",
    "    scaled_df = scaler.fit_transform(raw_df[scale_cols]) # scaler.inverse_transform(X)\n",
    "    scaled_df = pd.DataFrame(scaled_df , columns=scale_cols)\n",
    "\n",
    "    \n",
    "    label_np   = pd.DataFrame(scaled_df, columns=label_cols).to_numpy()\n",
    "    feature_np = pd.DataFrame(scaled_df, columns = feature_cols).to_numpy()\n",
    "\n",
    "    window_size = 40\n",
    "    x,y = make_sequence_dataset(feature_np, label_np, window_size)\n",
    "    x = survive_open(x,feature_cols,label_cols)\n",
    "\n",
    "    # train data 와 test data로 구분(7:3 비율) X,y : DataFrame\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    xtr,xval,ytr,yval = train_test_split(x,y,train_size=0.7,shuffle=True) #train:val = 7:3\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add( LSTM(128,\n",
    "                 activation = 'tanh',\n",
    "                 input_shape = xtr[0].shape)) #41,8\n",
    "\n",
    "    model.add(Dense (64, activation = 'linear'))\n",
    "    model.add(Dense (2, activation = 'linear'))\n",
    "    # model.summary()\n",
    "    # from livelossplot import PlotLossesKeras # pip install livelossplot\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae','acc'])\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    # model.fit(xtr,ytr, validation_data=(xval,yval), epochs=200,batch_size=32,callbacks=[early_stop,PlotLossesKeras()])\n",
    "    model.fit(xtr,ytr, validation_data=(xval,yval), epochs=200,batch_size=32,callbacks=[early_stop])\n",
    "    \n",
    "    # save\n",
    "    \n",
    "    import os\n",
    "    model_path = os.path.join(save_dir,f'{recent_date}_model.h5')\n",
    "    model.save(model_path)\n",
    "    print(f'saved to {model_path}')\n",
    "    \n",
    "    import joblib\n",
    "    scaler_path = os.path.join(save_dir,f'{recent_date}_scaler.pkl')\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f'saved to {scaler_path}')\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def inverse_scaling(pre,scaler,feature_cols=feature_cols,label_cols=label_cols):\n",
    "    index = []\n",
    "    zeros = np.zeros( (pre.shape[0],len(feature_cols)) )\n",
    "    for item in label_cols:\n",
    "        index.append(feature_cols.index(item) )\n",
    "    zeros[:,index] = pre\n",
    "    inverse_pred = scaler.inverse_transform(zeros)[:,index]\n",
    "    return inverse_pred\n",
    "\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "def get_predate(df,recent_day):\n",
    "    \n",
    "    pre_idx = df.reset_index()[df.index == pd.to_datetime(today)].index.values[0]\n",
    "    pre_date = df.iloc[pre_idx-1:pre_idx].index[0]\n",
    "    return pre_date.date()\n",
    "\n",
    "def load_model(df,recent_date,model_dir='./models'):\n",
    "    \n",
    "    pre_date = get_predate(df,recent_date)\n",
    "    \n",
    "    model_path  = os.path.join(model_dir,f'{str(pre_date)}_model.h5') \n",
    "    scaler_path = os.path.join(model_dir,f'{str(pre_date)}_scaler.pkl')\n",
    "    \n",
    "    if not (os.path.exists(model_path) and os.path.exists(scaler_path) ):\n",
    "        train_save(df,pre_date)\n",
    "    \n",
    "    model  = tf.keras.models.load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return model, scaler\n",
    "\n",
    "def predict(model,scaler,df,today):\n",
    "    \n",
    "    x = df.loc[:pd.to_datetime(today)][-41:]\n",
    "    x = scaler.transform(x)\n",
    "    x = survive_open(np.array([x]),feature_cols,label_cols)\n",
    "    y = model(x)\n",
    "    is_y = inverse_scaling(y,scaler) # inverse-scaled  \n",
    "    high,low = is_y[0][0],is_y[0][1]\n",
    "    return high,low\n",
    "    \n",
    "\n",
    "from datetime import datetime\n",
    "import FinanceDataReader as fdr \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "today = datetime.today().date()\n",
    "\n",
    "stock_name = \"TQQQ\"\n",
    "df = fdr.DataReader(stock_name)\n",
    "recent_date = df[-1:].index[0].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6d44b8-7ac6-4ee6-a842-201c826399e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime(2022,2,11).date()\n",
    "recent_date = datetime(2022,2,11).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f43ae5-4a35-4688-b744-7999c3245e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 high        low\n",
      "2022-02-11  59.009015  53.875462\n"
     ]
    }
   ],
   "source": [
    "if today != recent_date: # not open\n",
    "    train_save(df,recent_date)\n",
    "\n",
    "else: # today == recent_day # open (11:30~12:00)\n",
    "    # open_price = df[today_date].Open\n",
    "    \n",
    "    # pre_date     = get_predate(df,recent_date)\n",
    "    # model,scaler = load_model(pre_date)\n",
    "    model,scaler = load_model(df,recent_date)\n",
    "\n",
    "    # model,scaler = model_load(f\"{str(today)}_model.onnx\")\n",
    "    \n",
    "    high,low = predict(model,scaler,df,today)\n",
    "    \n",
    "    pre = pd.DataFrame({'high':[high],'low':[low]},columns=['high','low'],index=[today]);print(pre)\n",
    "    pre.to_csv(f'{today}_{stock_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f005f081-ba34-4660-851b-fe0d4052899e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-11-92b1818a4d2e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-92b1818a4d2e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    date(2021,int(02),12)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "date(2021,int(2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d316c18d-2c0a-4827-8c5c-15cf563ab00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rsub__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " 'ctime',\n",
       " 'day',\n",
       " 'fromordinal',\n",
       " 'fromtimestamp',\n",
       " 'isocalendar',\n",
       " 'isoformat',\n",
       " 'isoweekday',\n",
       " 'max',\n",
       " 'min',\n",
       " 'month',\n",
       " 'replace',\n",
       " 'resolution',\n",
       " 'strftime',\n",
       " 'timetuple',\n",
       " 'today',\n",
       " 'toordinal',\n",
       " 'weekday',\n",
       " 'year']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c564890-4ed6-4c95-9395-013cfaf249f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 8, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime                                                                                                                                                          \n",
    "datetime.strptime(\"2021-08-08\", \"%Y-%m-%d\").date()                                                                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f9059f7-27e9-4c19-a49a-2f3b7c8a80ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datetime.datetime'; 'datetime' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-931804d75d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from datetime import datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromisoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2020-07-18'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datetime.datetime'; 'datetime' is not a package"
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "from datetime.datetime import date\n",
    "date.fromisoformat('2020-07-18')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
